{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from doclayout_yolo import YOLOv10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "filepath = hf_hub_download(repo_id=\"juliozhao/DocLayout-YOLO-DocStructBench\", filename=\"doclayout_yolo_docstructbench_imgsz1024.pt\")\n",
    "\n",
    "model = YOLOv10(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Download and initialize the model\n",
    "filepath = hf_hub_download(\n",
    "    repo_id=\"juliozhao/DocLayout-YOLO-DocStructBench\", \n",
    "    filename=\"doclayout_yolo_docstructbench_imgsz1024.pt\"\n",
    ")\n",
    "model = YOLOv10(filepath)\n",
    "\n",
    "def convert_pdf_to_images(pdf_path):\n",
    "    \"\"\"Convert PDF to images using pdf2image\"\"\"\n",
    "    return pdf2image.convert_from_path(pdf_path)\n",
    "\n",
    "def process_pdf_directory(pdf_dir, output_dir):\n",
    "    \"\"\"Process all PDFs in a directory\"\"\"\n",
    "    pdf_dir = Path(pdf_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    for pdf_file in pdf_dir.glob(\"*.pdf\"):\n",
    "        # Create output subdirectory for this PDF\n",
    "        pdf_output_dir = output_dir / pdf_file.stem\n",
    "        pdf_output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Convert PDF to images\n",
    "        images = convert_pdf_to_images(pdf_file)\n",
    "        \n",
    "        # Process each page\n",
    "        for i, image in enumerate(images):\n",
    "            # Convert PIL Image to OpenCV format\n",
    "            opencv_image = cv2.cvtColor(numpy.array(image), cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Save the intermediate image\n",
    "            image_path = pdf_output_dir / f\"page_{i+1}.jpg\"\n",
    "            cv2.imwrite(str(image_path), opencv_image)\n",
    "            \n",
    "            # Perform layout detection\n",
    "            det_res = model.predict(\n",
    "                str(image_path),\n",
    "                imgsz=1024,\n",
    "                conf=0.2,\n",
    "                device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "            )\n",
    "            \n",
    "            # Save annotated result\n",
    "            annotated_frame = det_res[0].plot(pil=True, line_width=5, font_size=20)\n",
    "            result_path = pdf_output_dir / f\"page_{i+1}_annotated.jpg\"\n",
    "            cv2.imwrite(str(result_path), annotated_frame)\n",
    "\n",
    "# Usage\n",
    "pdf_directory = \"data\"  # Your PDF directory\n",
    "output_directory = \"output\"  # Where to save results\n",
    "process_pdf_directory(pdf_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markitdown import MarkItDown\n",
    "from doclayout_yolo import YOLOv10\n",
    "from huggingface_hub import hf_hub_download\n",
    "import json\n",
    "from pathlib import Path\n",
    "import fitz\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pdf2image\n",
    "import numpy\n",
    "import torch\n",
    "import tempfile\n",
    "\n",
    "\n",
    "\n",
    "def convert_pdf_to_images(pdf_path):\n",
    "    \"\"\"Convert PDF to images using pdf2image\"\"\"\n",
    "    return pdf2image.convert_from_path(pdf_path)\n",
    "\n",
    "def select_boxes(det_res, image):\n",
    "    boxes = det_res[0].boxes\n",
    "    for _, box in enumerate(boxes):\n",
    "        # Get box coordinates\n",
    "        x, y, w, h = map(int, box.xywh[0].tolist())\n",
    "        cls = int(box.cls[0])\n",
    "        cls_name = det_res[0].names[cls]\n",
    "        print(cls_name)\n",
    "\n",
    "        if cls_name not in ['figure', 'formula', 'table']:\n",
    "            continue\n",
    "        conf = float(box.conf[0])\n",
    "        \n",
    "        # Calculate crop coordinates\n",
    "        x1 = max(0, x - w//2)\n",
    "        y1 = max(0, y - h//2)\n",
    "        x2 = min(image.shape[1], x + w//2)\n",
    "        y2 = min(image.shape[0], y + h//2)\n",
    "        \n",
    "        # Crop the image\n",
    "        cropped = image[int(y1):int(y2), int(x1):int(x2)]\n",
    "        yield cropped, cls_name, conf, box\n",
    "\n",
    "\n",
    "def process_pdf_directory(pdf_dir, output_dir):\n",
    "    \"\"\"Process all PDFs in a directory\"\"\"\n",
    "    pdf_dir = Path(pdf_dir)\n",
    "    print(pdf_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Initialize MarkItDown\n",
    "    md = MarkItDown()\n",
    "    \n",
    "    for pdf_file in pdf_dir.glob(\"*.pdf\"):\n",
    "        print(pdf_file)\n",
    "        pdf_output_dir = output_dir / pdf_file.stem\n",
    "        pdf_output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Open PDF with PyMuPDF for page handling\n",
    "        pdf_document = fitz.open(pdf_file)\n",
    "        \n",
    "        # Create temporary directory for single pages\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            temp_path = Path(temp_dir)\n",
    "            \n",
    "            # Convert PDF to images for YOLO processing\n",
    "            images = convert_pdf_to_images(pdf_file)\n",
    "            \n",
    "            # Process each page\n",
    "            for i, (image, pdf_page) in enumerate(zip(images, pdf_document)):\n",
    "                # Create single page PDF for MarkItDown\n",
    "                new_pdf = fitz.open()\n",
    "                new_pdf.insert_pdf(pdf_document, from_page=i, to_page=i)\n",
    "                temp_pdf_path = temp_path / f\"page_{i + 1}.pdf\"\n",
    "                new_pdf.save(temp_pdf_path)\n",
    "                \n",
    "                # Extract text using MarkItDown for this page\n",
    "                try:\n",
    "                    md_result = md.convert(str(temp_pdf_path))\n",
    "                    page_text = md_result.text_content\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting text from page {i + 1}: {str(e)}\")\n",
    "                    page_text = \"\"\n",
    "                \n",
    "                new_pdf.close()\n",
    "                \n",
    "                # Process image with YOLO\n",
    "                opencv_image = cv2.cvtColor(numpy.array(image), cv2.COLOR_RGB2BGR)\n",
    "                image_path = pdf_output_dir / f\"page_{i+1}.jpg\"\n",
    "                cv2.imwrite(str(image_path), opencv_image)\n",
    "                \n",
    "                det_res = model.predict(\n",
    "                    str(image_path),\n",
    "                    imgsz=1024,\n",
    "                    conf=0.2,\n",
    "                    device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "                )\n",
    "                \n",
    "                # Process detection results\n",
    "                page_data = {\n",
    "                    # List to store all detected regions on the page\n",
    "                    \"regions\": [],\n",
    "                    # Save markdown text file and store path\n",
    "                    \"markdown_path\": str(pdf_output_dir / f\"page_{i+1}.md\")\n",
    "                }\n",
    "                \n",
    "                # Write markdown file\n",
    "                with open(page_data[\"markdown_path\"], \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(page_text.strip() if page_text else \"\")\n",
    "                # Get boxes and their classes\n",
    "\n",
    "               \n",
    "\n",
    "                cropped_images = list(select_boxes(det_res, opencv_image))\n",
    "                \n",
    "                for cropped, cls_name, conf, box in cropped_images:\n",
    "                    region_path = pdf_output_dir / f\"page_{i+1}_{cls_name}_{len(page_data['regions'])}.jpg\"\n",
    "                    cv2.imwrite(str(region_path), cropped)\n",
    "                    region_data = {\n",
    "                            \"type\": cls_name,\n",
    "                            \"confidence\": conf,\n",
    "                            \"bbox\": box.xywh[0].tolist(),\n",
    "                            \"region_image_path\": str(region_path)\n",
    "                        }\n",
    "                    page_data[\"regions\"].append(region_data)\n",
    "\n",
    "\n",
    "                # for box in boxes:\n",
    "                #     bbox = box.xywh[0].tolist()\n",
    "                #     conf = float(box.conf[0])\n",
    "                #     cls = int(box.cls[0])\n",
    "                #     cls_name = det_res[0].names[cls]\n",
    "                    \n",
    "                    # Only extract regions for specific types\n",
    "                    # # if cls_name in ['figure', 'table', 'isolate_formula']:\n",
    "                    #     region_img = opencv_image.copy()\n",
    "                    #     x, y, w, h = map(int, bbox)\n",
    "                    #     region_img = cv2.rectangle(region_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                        \n",
    "                       \n",
    "                        # else:\n",
    "                        #     region_data = {\n",
    "                        #         \"type\": cls_name,\n",
    "                        #         \"confidence\": conf,\n",
    "                        #         \"bbox\": bbox\n",
    "                        #     }\n",
    "                    \n",
    "                   \n",
    "                \n",
    "                # Save JSON for this page\n",
    "                json_path = pdf_output_dir / f\"page_{i+1}.json\"\n",
    "                with open(json_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(page_data, f, ensure_ascii=False, indent=2)\n",
    "                \n",
    "                # Save annotated image\n",
    "                annotated_frame = det_res[0].plot(pil=True, line_width=5, font_size=20)\n",
    "                result_path = pdf_output_dir / f\"page_{i+1}_annotated.jpg\"\n",
    "                # cv2.imwrite(str(result_path), annotated_frame)\n",
    "            \n",
    "        pdf_document.close()\n",
    "\n",
    "# Initialize model\n",
    "filepath = hf_hub_download(\n",
    "    repo_id=\"juliozhao/DocLayout-YOLO-DocStructBench\", \n",
    "    filename=\"doclayout_yolo_docstructbench_imgsz1024.pt\"\n",
    ")\n",
    "model = YOLOv10(filepath)\n",
    "\n",
    "# Usage\n",
    "pdf_directory = \"../data/pdfs/\"\n",
    "output_directory = \"../data/output_pdfs/output_v5\"\n",
    "process_pdf_directory(pdf_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
